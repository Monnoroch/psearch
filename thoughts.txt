Мысли.

1. Загрузчик.
Это простая штука, которая должна принимать массив урлов и опционально зарезолвленные ip для них, делать http GET и возвращать
Код ответа, контент, его хеш и длительность запроса.
Стоит за балансором, если падает, балансер отправит запрос на следующий.

2. Резолвер.
Это штука чуть сложнее, которая принимает массив хостов и возвращает массив ip-адресов для каждого хоста, и длительность резолва.
Сложнее оно потому, что кеширует.
Стоит за балансором, если падает, балансер отправит запрос на следующий.

3. Хранилище.
Это сложная штука с простым интерфейсом: Find, Read, Write url.
Тут инкапсулированы все проблемы с хранением, надежностью, репликацией.
Система состоит из фронта и множества нод.
Каждая нода должна состоять из мастера и реплик, одна из которых становится мастером при его падении.
Фронт обменивается хартбитами с мастерами и следит, когда какой упал.
Новые ноды сообщают о себе фронту сами а он их назначает новым мастером или чьей-то репликой.
Если реплика упала, не нужно сразу ее мастеру назначать первую попавшуюся новую машину, скорее всего, она поднимется в течении нескольких секунд и на нее не нужно будет ничего скачивать.
Если падает реплика ноды, то ничего страшного, она поднимется, подцепит фронт и он ее, если она поднялась быстро, назначит к тому же мастеру, у которого она была. Если медленно, и то место занято, то ну ок, фронт решит, кем она будет.
Если падает мастер, то фронт назначает мастером одну из его реплик. Если он быстро поднимется, то станет репликой этого нового мастера. Если медленно -- фронт назначит его кем-то на общих основаниях. Незаконченный чанк будет потерян.
Если упадет фронт, то все, тут только ждать, когда он снова поднимется :)
Так что, надо, чтобы он поднимался быстро.

4. Заботливый скачиватель.
Это сервис, который прокачивает присланные урлы, при этом не слишком нагружая каждый конкретный хост.
Интерфейс простой, но асинхонный: принимает массив урлов, говорит ОК. Потом его можно просить отдать то, что он к текущему моменту выкачал.
Возвращает то же, что отдает загрузчик, только без длительностей (они нужны именно тут).
Может опционально пользоваться резолвером, чтобы оставлять меньше работы загрузчикам.
Сервис стоит за балансером с консистент-хешингом по хостам, если падает, то нагрузка перенаправляется на следующий инстанс. Данные, не положенные в хранилище теряются, это фиг с ним, их мало должно быть в каждый конкретный момент.
Очереди урлов, увы, тоже. С этим можно справиться, если очереди сделать персистентными (положить в какой-нибудь редис).

5. Паук.
Это как раз алгоритм обхода интернета в ширину.
Его апи вообще тривиальное: принимает изначальный список урлов для прокачки и кладет в свою очередь.
Работает так:
В одном потоке вытаскивает из очереди сколько-то урлов и отдает в карегивер.
Во втором потоке опрашивает карегивер на предемт результатов, получает результаты, складывает в хранилище, выпаршивает из них урлы, фильтрует те, что есть в хранилище и локальных структурах данных, как скаченные или отправленные на скачивание, кладет оставшиеся урлы в свою очередь.
Тут надо помнить, шардов может быть много, поэтому "положить в свою очередь" -- это на самом деле с помощью консистент хешинга разделить урлы по шардам и отправить их на эти шарды (в том числе на себя) через апи-метод.
Стоит за балансером, единственный апи метод будет амортизирован по сетевой нагрузке так как он сам своим шардам рассылает порции пришедших урлов.
